{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import rec_parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "To obtain data, a recipe is parsed to identify dictionary matches. Each dictionary entry corresponds to an index in recipe space. So, each recipe is represented as a vector in recipe space of dimension 4060. Beginnning with a set of 15768 recipe vectors. 10% of those vectors, at equal intervals are reserved as test data. The result should be 4 matrices, trainX representing 14191 recipe vectors, trainY representing binary labels for each of those recipes, testX representing 1577 recipe vectors on which to test, and testY reresenting labels for the test data. For the label matrices, a 1 in column 0 represents 'dinner', while a 1 in column 1 represents 'non-dinner'.\n",
    "\n",
    "A simple improvement here would be to calculate labels before splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data is ready.\n",
      "trainX shape = (14191, 4060)\n",
      "traiY shape = (14191, 2)\n",
      "testX shape = (1577, 4060)\n",
      "testY shape = (1577, 2)\n"
     ]
    }
   ],
   "source": [
    "data = rec_parse.parse_recipes()\n",
    "trainX, testX = rec_parse.split(data)\n",
    "\n",
    "trainY = np.zeros((len(data)-1577, 2), dtype=np.int)\n",
    "testY = np.zeros([1577, 2], dtype=np.int)\n",
    "\n",
    "for ind, row in enumerate(trainY):\n",
    "    if ind > 150:\n",
    "        trainY[ind][1] = 1\n",
    "    else:\n",
    "        trainY[ind][0] = 1\n",
    "\n",
    "for ind, row in enumerate(testY):\n",
    "    if ind > 15:\n",
    "        testY[ind][1] = 1\n",
    "    else:\n",
    "        testY[ind][0] = 1\n",
    "        \n",
    "print(\"Your data is ready.\")\n",
    "print(\"trainX shape =\", trainX.shape)\n",
    "print(\"traiY shape =\", trainY.shape)\n",
    "print(\"testX shape =\", testX.shape)\n",
    "print(\"testY shape =\", testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numFeatures = trainX.shape[1]\n",
    "numLabels = trainY.shape[1]\n",
    "\n",
    "numEpochs = 500\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=trainX.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable/read:0\", shape=(4060, 2), dtype=float32)\n",
      "Tensor(\"Variable_1/read:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=(np.sqrt(6/numFeatures+\n",
    "                                                         numLabels+1)),\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=(np.sqrt(6/numFeatures+numLabels+1)),\n",
    "                                    name=\"bias\"))\n",
    "\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "for i in tf.global_variables():\n",
    "    print(i)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm\n",
    "Multiply trainX(14191, 4060) by weights(4060, 2), resulting in apply_weights_OP(14191, 2).\n",
    "And add the bias(1, 2), resulting in add_bias_OP(14191, 2)\n",
    "\n",
    "Activate using rectified linear:\n",
    "f(x) = max(0, x)\n",
    "\n",
    "Calculate loss using Mean Squared Error:\n",
    "$\\frac{1}{n}\\sum_{i=0}^n ({y}_{estimated}-{y}_{real})^2$\n",
    "\n",
    "Optimize using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEEDFORWARD ALGORITHM\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\")\n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")\n",
    "\n",
    "# COST FUNCTION i.e. MEAN SQUARED ERROR\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "# OPTIMIZATION ALGORITHM i.e. GRADIENT DESCENT\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.354309\n",
      "step 0, cost 8259.3\n",
      "step 0, change in cost 8259.3\n",
      "step 10, training accuracy 0.919174\n",
      "step 10, cost 1357.69\n",
      "step 10, change in cost 6901.61\n",
      "step 20, training accuracy 0.9518\n",
      "step 20, cost 828.3\n",
      "step 20, change in cost 529.388\n",
      "step 30, training accuracy 0.964978\n",
      "step 30, cost 618.135\n",
      "step 30, change in cost 210.165\n",
      "step 40, training accuracy 0.971602\n",
      "step 40, cost 501.364\n",
      "step 40, change in cost 116.771\n",
      "step 50, training accuracy 0.976464\n",
      "step 50, cost 422.81\n",
      "step 50, change in cost 78.5538\n",
      "step 60, training accuracy 0.979212\n",
      "step 60, cost 376.849\n",
      "step 60, change in cost 45.9611\n",
      "step 70, training accuracy 0.981467\n",
      "step 70, cost 342.636\n",
      "step 70, change in cost 34.2129\n",
      "step 80, training accuracy 0.983017\n",
      "step 80, cost 317.992\n",
      "step 80, change in cost 24.6441\n",
      "step 90, training accuracy 0.984427\n",
      "step 90, cost 299.151\n",
      "step 90, change in cost 18.8412\n",
      "step 100, training accuracy 0.985061\n",
      "step 100, cost 285.704\n",
      "step 100, change in cost 13.4466\n",
      "step 110, training accuracy 0.985413\n",
      "step 110, cost 274.75\n",
      "step 110, change in cost 10.9538\n",
      "step 120, training accuracy 0.985836\n",
      "step 120, cost 265.172\n",
      "step 120, change in cost 9.57834\n",
      "step 130, training accuracy 0.986118\n",
      "step 130, cost 256.856\n",
      "step 130, change in cost 8.31635\n",
      "step 140, training accuracy 0.986259\n",
      "step 140, cost 249.62\n",
      "step 140, change in cost 7.23553\n",
      "step 150, training accuracy 0.986893\n",
      "step 150, cost 243.268\n",
      "step 150, change in cost 6.35172\n",
      "step 160, training accuracy 0.986964\n",
      "step 160, cost 237.73\n",
      "step 160, change in cost 5.53839\n",
      "step 170, training accuracy 0.987034\n",
      "step 170, cost 232.827\n",
      "step 170, change in cost 4.90347\n",
      "step 180, training accuracy 0.987175\n",
      "step 180, cost 228.597\n",
      "step 180, change in cost 4.22955\n",
      "step 190, training accuracy 0.987457\n",
      "step 190, cost 224.89\n",
      "step 190, change in cost 3.70712\n",
      "step 200, training accuracy 0.987527\n",
      "step 200, cost 221.522\n",
      "step 200, change in cost 3.36824\n",
      "step 210, training accuracy 0.987527\n",
      "step 210, cost 218.501\n",
      "step 210, change in cost 3.0208\n",
      "step 220, training accuracy 0.987598\n",
      "step 220, cost 215.684\n",
      "step 220, change in cost 2.81682\n",
      "step 230, training accuracy 0.987598\n",
      "step 230, cost 213.001\n",
      "step 230, change in cost 2.68288\n",
      "step 240, training accuracy 0.987668\n",
      "step 240, cost 210.45\n",
      "step 240, change in cost 2.55112\n",
      "step 250, training accuracy 0.987739\n",
      "step 250, cost 208.065\n",
      "step 250, change in cost 2.38458\n",
      "step 260, training accuracy 0.987739\n",
      "step 260, cost 205.878\n",
      "step 260, change in cost 2.18774\n",
      "step 270, training accuracy 0.98788\n",
      "step 270, cost 203.863\n",
      "step 270, change in cost 2.01465\n",
      "step 280, training accuracy 0.98795\n",
      "step 280, cost 201.971\n",
      "step 280, change in cost 1.89217\n",
      "step 290, training accuracy 0.98795\n",
      "step 290, cost 200.128\n",
      "step 290, change in cost 1.84282\n",
      "step 300, training accuracy 0.98795\n",
      "step 300, cost 198.332\n",
      "step 300, change in cost 1.79613\n",
      "step 310, training accuracy 0.98795\n",
      "step 310, cost 196.739\n",
      "step 310, change in cost 1.59308\n",
      "step 320, training accuracy 0.988021\n",
      "step 320, cost 195.292\n",
      "step 320, change in cost 1.44635\n",
      "step 330, training accuracy 0.988232\n",
      "step 330, cost 193.895\n",
      "step 330, change in cost 1.39751\n",
      "step 340, training accuracy 0.988302\n",
      "step 340, cost 192.514\n",
      "step 340, change in cost 1.38101\n",
      "step 350, training accuracy 0.988302\n",
      "step 350, cost 191.147\n",
      "step 350, change in cost 1.36705\n",
      "step 360, training accuracy 0.988302\n",
      "step 360, cost 189.804\n",
      "step 360, change in cost 1.34334\n",
      "step 370, training accuracy 0.988373\n",
      "step 370, cost 188.514\n",
      "step 370, change in cost 1.28915\n",
      "step 380, training accuracy 0.988373\n",
      "step 380, cost 187.299\n",
      "step 380, change in cost 1.2153\n",
      "step 390, training accuracy 0.988443\n",
      "step 390, cost 186.144\n",
      "step 390, change in cost 1.15515\n",
      "step 400, training accuracy 0.988514\n",
      "step 400, cost 185.029\n",
      "step 400, change in cost 1.11531\n",
      "step 410, training accuracy 0.988514\n",
      "step 410, cost 183.944\n",
      "step 410, change in cost 1.08475\n",
      "step 420, training accuracy 0.988514\n",
      "step 420, cost 182.888\n",
      "step 420, change in cost 1.05582\n",
      "step 430, training accuracy 0.988514\n",
      "step 430, cost 181.859\n",
      "step 430, change in cost 1.02908\n",
      "step 440, training accuracy 0.988514\n",
      "step 440, cost 180.853\n",
      "step 440, change in cost 1.00577\n",
      "step 450, training accuracy 0.988514\n",
      "step 450, cost 179.875\n",
      "step 450, change in cost 0.978607\n",
      "step 460, training accuracy 0.988514\n",
      "step 460, cost 178.937\n",
      "step 460, change in cost 0.937988\n",
      "step 470, training accuracy 0.988584\n",
      "step 470, cost 178.053\n",
      "step 470, change in cost 0.883392\n",
      "step 480, training accuracy 0.988584\n",
      "step 480, cost 177.233\n",
      "step 480, change in cost 0.819794\n",
      "step 490, training accuracy 0.988584\n",
      "step 490, cost 176.48\n",
      "step 490, change in cost 0.753204\n",
      "final accuracy on test set: 0.989854\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEYCAYAAAD4czk4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110bb2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training epochs\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_OP)\n",
    "\n",
    "    ###########################\n",
    "    ### GRAPH LIVE UPDATING ###\n",
    "    ###########################\n",
    "\n",
    "    epoch_values=[]\n",
    "    accuracy_values=[]\n",
    "    cost_values=[]\n",
    "    \n",
    "    # Turn on interactive plotting\n",
    "    plt.ion()\n",
    "    # Create the main, super plot\n",
    "    fig = plt.figure()\n",
    "    # Create two subplots on their own axes and give titles\n",
    "    ax1 = plt.subplot(\"211\")\n",
    "    ax1.set_title(\"TRAINING ACCURACY\", fontsize=10)\n",
    "    ax2 = plt.subplot(\"212\")\n",
    "    ax2.set_title(\"TRAINING COST\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    #####################\n",
    "    ### RUN THE GRAPH ###\n",
    "    #####################\n",
    "\n",
    "    ## Ops for vizualization\n",
    "    # argmax(activation_OP, 1) gives the label our model thought was most likely\n",
    "    # argmax(yGold, 1) is the correct label\n",
    "    correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "    # False is 0 and True is 1, what was our average?\n",
    "    accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "    # Summary op for regression output\n",
    "    activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "    # Summary op for accuracy\n",
    "    accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "    # Summary op for cost\n",
    "    cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "    # Summary ops to check how variables (W, b) are updating after each iteration\n",
    "    weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "    biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "    # Merge all summaries\n",
    "    all_summary_OPS = tf.summary.merge_all()\n",
    "    # Summary writer\n",
    "    writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)\n",
    "\n",
    "    # Initialize reporting variables\n",
    "    cost = 0\n",
    "    diff = 1\n",
    "\n",
    "    for i in range(numEpochs): \n",
    "        if i > 1 and diff < .0001:\n",
    "            print(\"change in cost %g; convergence.\"%diff)\n",
    "            break\n",
    "        else:\n",
    "            # Run training step\n",
    "            step = sess.run(training_OP, feed_dict={X: trainX, yGold: trainY})\n",
    "            \n",
    "            # Report occasional stats\n",
    "            if i % 10 == 0:\n",
    "                # Add epoch to epoch_values\n",
    "                epoch_values.append(i)\n",
    "                # Generate accuracy stats on test data\n",
    "                summary_results, train_accuracy, newCost = sess.run(\n",
    "                    [all_summary_OPS, accuracy_OP, cost_OP],\n",
    "                    feed_dict={X: trainX, yGold: trainY}\n",
    "                )\n",
    "                # Add accuracy to live graphing variable\n",
    "                accuracy_values.append(train_accuracy)\n",
    "                # Add cost to live graphing variable\n",
    "                cost_values.append(newCost)\n",
    "                # Write summary stats to writer\n",
    "                writer.add_summary(summary_results, i)\n",
    "                # Re-assign values for variables\n",
    "                diff = abs(newCost - cost)\n",
    "                cost = newCost\n",
    "\n",
    "                #generate print statements\n",
    "                print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "                print(\"step %d, cost %g\"%(i, newCost))\n",
    "                print(\"step %d, change in cost %g\"%(i, diff))\n",
    "\n",
    "                # Plot progress to our two subplots\n",
    "                accuracyLine, = ax1.plot(epoch_values, accuracy_values)\n",
    "                costLine, = ax2.plot(epoch_values, cost_values)\n",
    "                fig.canvas.draw()\n",
    "                time.sleep(1)\n",
    "    \n",
    "    # Create Saver\n",
    "    saver = tf.train.Saver()   \n",
    "    saver.save(sess, '/tmp/dinner-model')\n",
    "\n",
    "    # How well do we perform on held-out test data?\n",
    "    print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP,\n",
    "                                                         feed_dict={X: testX,\n",
    "                                                                    yGold: testY})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import new set\n",
    "Now we'll bring in the 100 most recent recipes published to Cookpad and return those which are identified by the algorithm as 'dinner'so that we can subject them to human analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape = (1001, 4060)\n"
     ]
    }
   ],
   "source": [
    "data = rec_parse.parse_newest_recipes() \n",
    "print(\"data shape =\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "53\n",
      "234\n",
      "344\n",
      "482\n",
      "488\n",
      "527\n",
      "537\n",
      "539\n",
      "541\n",
      "612\n",
      "644\n",
      "692\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as lolo:\n",
    "    saver.restore(lolo, '/tmp/dinner-model')\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    predictions = lolo.run(activation_OP, feed_dict={X: data})\n",
    "    print(predictions[0])\n",
    "    for index, i in enumerate(predictions):\n",
    "        if i[0] > .9:\n",
    "            print(index, i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
